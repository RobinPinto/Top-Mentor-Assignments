#1. Why is handling categorical data important in machine learning?


'''
Answer:

Handling categorical data is vital in machine learning because most algorithms require numerical input, 
and categorical data often holds valuable information. 
Proper encoding prevents errors, enhances model performance, and ensures fair and accurate predictions, 
improving the overall quality and interpretability of machine learning models.

'''


#2.What are some examples of categorical values?

'''
Answer:

Categorical values are non-numerical values.
example : colors, lables , gender,Marital status etc

'''

#3. How can you convert categorical values into numerical format in machine learning?

#Answer:

'''In ML, to convert categorical values to numerical values we have to use
    1. Label Encoding
    2. One-Hot Encoding
    '''

#4. What are two common methods for converting categorical values into numerical format in machine learning?

'''
Answer:

#1.Label Encoding

#2.One-Hot Encoding

'''

#5. Explain Label Encoding and how it works.

'''

Label Encoding is a technique for converting categorical values into a numerical format in machine learning.
Label encoding will assign a unique number to each category.
Example:Red=0,Blue=1

'''
from sklearn.preprocessing import LabelEncoder


categories = ['red', 'blue', 'green', 'yellow', 'red', 'blue']

label_encoder = LabelEncoder()

encoded_labels = label_encoder.fit_transform(categories)

print("Original Categories:", categories)
print("Encoded Labels:", encoded_labels)

#6.What is One-Hot Encoding, and how does it differ from Label Encoding?

'''  
    #ONE HOT ENCODING                                                               #LABEL ENCODING
#Creates binary columns for each category(0,1)                              Assigns unique number to each category(0,1,2,3)
#It is lengthy                                                              It is easier compared to OHE
#More interpretable as separate column is created for each category         Less interpretable
#Will consume more computer space                                           will consume lesser computer space

'''

#7.What is the output of the pandas get_dummies() function?

'''get_dummies() is used to perform one-hot encoding
#get_dummies() belongs to pandas
#It will convert into the matrix format
#pandas.get_dummies() function outputs a DataFrame by default, 
where each unique category from the original categorical variable becomes a binary column.
'''

#8.Can you provide an example of a dependent variable and its independent variables?

'''
#student exam score(dependent variable)


#(independent variables)
#study hours
#sleep hours
#study environment
#attendance etc

'''

#9. What are outliers, and how do they deviate from the majority of the data in a dataset?

'''
Outliers are data points or observations that significantly,
deviate from the majority of the data in a Dataset

It will arise due to variours reasons, including errors in data collection
measurement errors.

Odd value in a dataset indicates an outlier because its value
is significantly higher or lower compared to the rest of the data.

'''

#10. How can you customize the appearance of a pie chart in Matplotlib?


#creating a standard pie chart with some data

import matplotlib.pyplot as plt

empdata = {
   'Namrata':60000,
    'Tushar':70000,
    'Robin':100000,
    'Suman':50000,
    'Arpita':90000
}

salary = empdata.values()
labels = empdata.keys()

plt.pie(salary,labels=labels)
plt.show()

#customizing the appearance

import matplotlib.pyplot as plt

empdata = {
    'Namrata':60000,
    'Tushar':70000,
    'Robin':100000,
    'Suman':50000,
    'Arpita':90000
}

salary = empdata.values()
names = empdata.keys()


colors = ['Red','Yellow','lightskyblue','lightgreen','purple']
ex = [0,0,0.2,0,0]

plt.pie(salary,
        labels=names,
        autopct='%1.0f%%',
        colors=colors,
       shadow=True,
       explode=ex,
       wedgeprops={ 'linewidth':3,'edgecolor':'black'},
        textprops={'fontsize':20,'color':'blue'},
        radius=1.3,
        labeldistance=1.2
       )
plt.show()

